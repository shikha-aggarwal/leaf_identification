{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we find out name of the tree from shape of a leaf?\n",
    "\n",
    "### This is the second notebook. The first notebook, leaf_id_CNN.ipynb, can be found in the same folder as this.\n",
    "\n",
    "Dataset from: https://www.kaggle.com/c/leaf-classification/data\n",
    "\n",
    "#### Description\n",
    "The dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a Ô¨Åne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "#### Previous conclusion about data\n",
    "99 classes, 16 samples from each class.\n",
    "data per image - id, species, margin (64), shape (64), texture (64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.image as mpimg       # reading images to numpy arrays\n",
    "import matplotlib.pyplot as plt        # to plot any graph\n",
    "import matplotlib.patches as mpatches  # to draw a circle at the mean contour\n",
    "\n",
    "from skimage import measure            # to find shape contour\n",
    "from skimage import color\n",
    "import scipy.ndimage as ndi            # to determine shape centrality\n",
    "\n",
    "# matplotlib setup\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "\n",
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN\n",
    "Convolution layer, pooling, Convolution layer, pooling, dense layer, another dense layer for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = mpimg.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "all_image_data = load_images('./data/kaggle_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_image_data))\n",
    "print(len(all_image_data[0]), len(all_image_data[0][0]))\n",
    "print(len(all_image_data[1]), len(all_image_data[1][0]))\n",
    "\n",
    "## Turns out all the images are different sizes!\n",
    "## Have to deal with this before using in CNN because I am using dense layers as well \n",
    "## - doesn't matter for filter layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of code from here: https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization/comments\n",
    "# This loads and resizes images to uniform size\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    max_axis = max((0, 1), key=lambda i: img.size[i])\n",
    "    scale = max_dim / float(img.size[max_axis])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "def load_image_data(ids, data_path, max_dim=96, center=True):\n",
    "    # Input: an array of image ids to load from data_path\n",
    "    # Initialize the output array\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    for i, idee in enumerate(ids):\n",
    "        x = resize_img(load_img(os.path.join(data_path, str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "    return np.around(X / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to split the input images according to the ids given in features training set.\n",
    "# So we will read the training set to get the image ids of test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# standardize the data by setting the mean to 0 and std to 1\n",
    "all_data = pd.read_csv('./data/train.csv')\n",
    "label_col = all_data.pop('species')\n",
    "id_col = all_data.pop('id')\n",
    "data_standardized = pd.DataFrame(StandardScaler().fit(all_data).transform(all_data))\n",
    "data_standardized.insert(0, 'id', id_col, True)\n",
    "data_standardized.insert(1, 'species', label_col, True)\n",
    "\n",
    "#SPLIT\n",
    "data_train, data_test = train_test_split(data_standardized, test_size=0.1, random_state=1)\n",
    "data_train, data_val = train_test_split(data_train, test_size=0.1, random_state=1)\n",
    "\n",
    "y_all = data_standardized['species']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit(y_all).transform(data_train['species'])\n",
    "y_test = lb.fit(y_all).transform(data_test['species'])\n",
    "y_val = lb.fit(y_all).transform(data_val['species'])\n",
    "print(y_train.shape, y_test.shape, y_val.shape)\n",
    "\n",
    "X_train = data_train.drop(['id', 'species'], axis=1)\n",
    "X_test = data_test.drop(['id', 'species'], axis=1)\n",
    "X_val = data_val.drop(['id', 'species'], axis=1)\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "# Read corresponding images for test and train\n",
    "img_data_path = './data/kaggle_images/'\n",
    "X_train_images = load_image_data(data_train['id'], img_data_path)\n",
    "X_test_images = load_image_data(data_test['id'], img_data_path)\n",
    "X_val_images = load_image_data(data_val['id'], img_data_path)\n",
    "print(X_train_images.shape, X_test_images.shape, X_val_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://keras.io/examples/cifar10_cnn/\n",
    "\n",
    "x_train_model = X_train_images\n",
    "x_test_model = X_test_images\n",
    "x_val_model = X_val_images\n",
    "Y_train_model = y_train\n",
    "Y_test_model = y_test\n",
    "Y_val_model = y_val\n",
    "\n",
    "num_classes = 99\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train_model.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the model using RMSprop\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 99\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "# num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_leaf_combined_model_v2.h5'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_model, Y_train_model,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_model, Y_test_model),\n",
    "          shuffle=True)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_val_model, Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add given numerical features to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model():\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # First convolutional layer\n",
    "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = Concatenate()([x, numerical])\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "comb_model = combined_model()\n",
    "print('Model created!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "print('Training model...')\n",
    "history = comb_model.fit(x = {'image': X_train_images, 'numerical': X_train},\n",
    "                    y = y_train,\n",
    "                    batch_size = 100,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1\n",
    "                   )\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "combined_model_name = \"leafnet_combined.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, combined_model_name)\n",
    "comb_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = comb_model.evaluate(x = {'image': X_val_images, 'numerical': X_val}, y = Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 99\n",
    "epochs = 100\n",
    "\n",
    "print('Training model...')\n",
    "history = comb_model.fit(x = {'image': X_train_images, 'numerical': X_train},\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         validation_data=({'image': X_test_images, 'numerical': X_test}, Y_test_model),\n",
    "                         shuffle=True,\n",
    "                         verbose = 1\n",
    "                        )\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "combined_model_name = \"leafnet_combined_2.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, combined_model_name)\n",
    "comb_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = comb_model.evaluate(x = {'image': X_val_images, 'numerical': X_val}, y = Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
