{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we find out name of the tree from shape of a leaf?\n",
    "\n",
    "### This is the second notebook. The first notebook, leaf_id_CNN.ipynb, can be found in the same folder as this.\n",
    "\n",
    "Dataset from: https://www.kaggle.com/c/leaf-classification/data\n",
    "\n",
    "#### Description\n",
    "The dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a Ô¨Åne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "#### Previous conclusion about data\n",
    "99 classes, 16 samples from each class.\n",
    "data per image - id, species, margin (64), shape (64), texture (64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.image as mpimg       # reading images to numpy arrays\n",
    "import matplotlib.pyplot as plt        # to plot any graph\n",
    "import matplotlib.patches as mpatches  # to draw a circle at the mean contour\n",
    "\n",
    "from skimage import measure            # to find shape contour\n",
    "from skimage import color\n",
    "import scipy.ndimage as ndi            # to determine shape centrality\n",
    "\n",
    "# matplotlib setup\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (6, 6)      # setting default size of plots\n",
    "\n",
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN\n",
    "Convolution layer, pooling, Convolution layer, pooling, dense layer, another dense layer for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = mpimg.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "all_image_data = load_images('./data/kaggle_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584\n",
      "379 689\n",
      "614 905\n"
     ]
    }
   ],
   "source": [
    "print(len(all_image_data))\n",
    "print(len(all_image_data[0]), len(all_image_data[0][0]))\n",
    "print(len(all_image_data[1]), len(all_image_data[1][0]))\n",
    "\n",
    "## Turns out all the images are different sizes!\n",
    "## Have to deal with this before using in CNN because I am using dense layers as well \n",
    "## - doesn't matter for filter layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of code from here: https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization/comments\n",
    "# This loads and resizes images to uniform size\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    max_axis = max((0, 1), key=lambda i: img.size[i])\n",
    "    scale = max_dim / float(img.size[max_axis])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "def load_image_data(ids, data_path, max_dim=96, center=True):\n",
    "    # Input: an array of image ids to load from data_path\n",
    "    # Initialize the output array\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    for i, idee in enumerate(ids):\n",
    "        x = resize_img(load_img(os.path.join(data_path, str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "    return np.around(X / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 99) (99, 99) (90, 99)\n",
      "(801, 192) (99, 192) (90, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 96, 96, 1) (99, 96, 96, 1) (90, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now we want to split the input images according to the ids given in features training set.\n",
    "# So we will read the training set to get the image ids of test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# standardize the data by setting the mean to 0 and std to 1\n",
    "all_data = pd.read_csv('./data/train.csv')\n",
    "label_col = all_data.pop('species')\n",
    "id_col = all_data.pop('id')\n",
    "data_standardized = pd.DataFrame(StandardScaler().fit(all_data).transform(all_data))\n",
    "data_standardized.insert(0, 'id', id_col, True)\n",
    "data_standardized.insert(1, 'species', label_col, True)\n",
    "\n",
    "#SPLIT\n",
    "data_train, data_test = train_test_split(data_standardized, test_size=0.1, random_state=1)\n",
    "data_train, data_val = train_test_split(data_train, test_size=0.1, random_state=1)\n",
    "\n",
    "y_all = data_standardized['species']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit(y_all).transform(data_train['species'])\n",
    "y_test = lb.fit(y_all).transform(data_test['species'])\n",
    "y_val = lb.fit(y_all).transform(data_val['species'])\n",
    "print(y_train.shape, y_test.shape, y_val.shape)\n",
    "\n",
    "X_train = data_train.drop(['id', 'species'], axis=1)\n",
    "X_test = data_test.drop(['id', 'species'], axis=1)\n",
    "X_val = data_val.drop(['id', 'species'], axis=1)\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "# Read corresponding images for test and train\n",
    "img_data_path = './data/kaggle_images/'\n",
    "X_train_images = load_image_data(data_train['id'], img_data_path)\n",
    "X_test_images = load_image_data(data_test['id'], img_data_path)\n",
    "X_val_images = load_image_data(data_val['id'], img_data_path)\n",
    "print(X_train_images.shape, X_test_images.shape, X_val_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Copied from https://keras.io/examples/cifar10_cnn/\n",
    "\n",
    "x_train_model = X_train_images\n",
    "x_test_model = X_test_images\n",
    "x_val_model = X_val_images\n",
    "Y_train_model = y_train\n",
    "Y_test_model = y_test\n",
    "Y_val_model = y_val\n",
    "\n",
    "num_classes = 99\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train_model.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 801 samples, validate on 99 samples\n",
      "Epoch 1/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 4.5683 - acc: 0.0287 - val_loss: 4.4955 - val_acc: 0.0303\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 4.3073 - acc: 0.0499 - val_loss: 4.1307 - val_acc: 0.0808\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 3.8424 - acc: 0.1049 - val_loss: 3.6875 - val_acc: 0.2323\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 3.3214 - acc: 0.1910 - val_loss: 3.0806 - val_acc: 0.3838\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 2.8862 - acc: 0.2634 - val_loss: 2.5500 - val_acc: 0.4343\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 2.4771 - acc: 0.3333 - val_loss: 2.3096 - val_acc: 0.4040\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 2.1714 - acc: 0.4170 - val_loss: 2.1271 - val_acc: 0.4646\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 1.9482 - acc: 0.4657 - val_loss: 2.1859 - val_acc: 0.4040\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 1.8152 - acc: 0.5006 - val_loss: 1.9161 - val_acc: 0.4444\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 1.5982 - acc: 0.5531 - val_loss: 1.9641 - val_acc: 0.4444\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 1.4736 - acc: 0.5655 - val_loss: 1.8542 - val_acc: 0.4646\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 16s 20ms/step - loss: 1.3366 - acc: 0.6092 - val_loss: 1.8351 - val_acc: 0.5051\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 1.2204 - acc: 0.6317 - val_loss: 1.6819 - val_acc: 0.5051\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 1.1548 - acc: 0.6667 - val_loss: 1.7972 - val_acc: 0.5455\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 1.0752 - acc: 0.6692 - val_loss: 1.7560 - val_acc: 0.4949\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 1.0010 - acc: 0.6916 - val_loss: 1.7725 - val_acc: 0.5253\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 0.9300 - acc: 0.7316 - val_loss: 1.7009 - val_acc: 0.5657\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 0.8331 - acc: 0.7416 - val_loss: 1.7427 - val_acc: 0.5253\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.7973 - acc: 0.7553 - val_loss: 1.6712 - val_acc: 0.5556\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.7680 - acc: 0.7765 - val_loss: 1.6684 - val_acc: 0.5556\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 13s 17ms/step - loss: 0.7531 - acc: 0.7603 - val_loss: 1.6677 - val_acc: 0.5758\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.6829 - acc: 0.7903 - val_loss: 1.7015 - val_acc: 0.5960\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.6408 - acc: 0.7928 - val_loss: 1.7193 - val_acc: 0.5657\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.5755 - acc: 0.8127 - val_loss: 1.6309 - val_acc: 0.5657\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.5237 - acc: 0.8302 - val_loss: 1.7699 - val_acc: 0.5859\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.5664 - acc: 0.7990 - val_loss: 2.0920 - val_acc: 0.5253\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.4857 - acc: 0.8564 - val_loss: 1.7642 - val_acc: 0.5859\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.4432 - acc: 0.8527 - val_loss: 1.8689 - val_acc: 0.5354\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.4709 - acc: 0.8427 - val_loss: 1.9996 - val_acc: 0.5253\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.3832 - acc: 0.8777 - val_loss: 1.8011 - val_acc: 0.5657\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.3796 - acc: 0.8677 - val_loss: 1.8945 - val_acc: 0.5657\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.3809 - acc: 0.8727 - val_loss: 1.8955 - val_acc: 0.5960\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.3059 - acc: 0.9014 - val_loss: 2.1345 - val_acc: 0.4848\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.2851 - acc: 0.8964 - val_loss: 1.9270 - val_acc: 0.5758\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.2845 - acc: 0.9126 - val_loss: 2.0243 - val_acc: 0.5354\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.2585 - acc: 0.9176 - val_loss: 1.9988 - val_acc: 0.5657\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.2563 - acc: 0.9089 - val_loss: 2.1883 - val_acc: 0.5758\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.2504 - acc: 0.9151 - val_loss: 2.0392 - val_acc: 0.5657\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.2241 - acc: 0.9313 - val_loss: 2.2505 - val_acc: 0.5556\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.2125 - acc: 0.9238 - val_loss: 2.3154 - val_acc: 0.5758\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.2026 - acc: 0.9351 - val_loss: 2.3402 - val_acc: 0.5556\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.2118 - acc: 0.9238 - val_loss: 2.3060 - val_acc: 0.5657\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1933 - acc: 0.9438 - val_loss: 2.2938 - val_acc: 0.5657\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1503 - acc: 0.9538 - val_loss: 2.3367 - val_acc: 0.5960\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1610 - acc: 0.9438 - val_loss: 2.4047 - val_acc: 0.5960\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1564 - acc: 0.9451 - val_loss: 2.3314 - val_acc: 0.6263\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1522 - acc: 0.9526 - val_loss: 2.4152 - val_acc: 0.5758\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1593 - acc: 0.9476 - val_loss: 2.2097 - val_acc: 0.6061\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1147 - acc: 0.9700 - val_loss: 2.5992 - val_acc: 0.5455\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.1343 - acc: 0.9501 - val_loss: 2.4520 - val_acc: 0.5859\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.0970 - acc: 0.9638 - val_loss: 2.5936 - val_acc: 0.5556\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1188 - acc: 0.9613 - val_loss: 2.4735 - val_acc: 0.5758\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0935 - acc: 0.9750 - val_loss: 2.5575 - val_acc: 0.5657\n",
      "Epoch 54/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0966 - acc: 0.9650 - val_loss: 2.5750 - val_acc: 0.6061\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.1062 - acc: 0.9600 - val_loss: 2.4607 - val_acc: 0.5758\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 14s 17ms/step - loss: 0.0838 - acc: 0.9700 - val_loss: 2.5543 - val_acc: 0.6061\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0731 - acc: 0.9763 - val_loss: 2.3948 - val_acc: 0.5657\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 16s 19ms/step - loss: 0.0963 - acc: 0.9738 - val_loss: 2.4937 - val_acc: 0.5859\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 15s 18ms/step - loss: 0.0813 - acc: 0.9700 - val_loss: 2.5310 - val_acc: 0.5859\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0582 - acc: 0.9813 - val_loss: 2.8281 - val_acc: 0.5556\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0820 - acc: 0.9750 - val_loss: 2.6238 - val_acc: 0.5859\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0617 - acc: 0.9788 - val_loss: 2.7051 - val_acc: 0.5455\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 0.0472 - acc: 0.9838 - val_loss: 2.6821 - val_acc: 0.5758\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0656 - acc: 0.9800 - val_loss: 2.9085 - val_acc: 0.5657\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0613 - acc: 0.9725 - val_loss: 2.6140 - val_acc: 0.5859\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0576 - acc: 0.9813 - val_loss: 2.5785 - val_acc: 0.5859\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0697 - acc: 0.9788 - val_loss: 2.5543 - val_acc: 0.6162\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0396 - acc: 0.9850 - val_loss: 2.7813 - val_acc: 0.5556\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0397 - acc: 0.9900 - val_loss: 2.8168 - val_acc: 0.5657\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 14s 18ms/step - loss: 0.0416 - acc: 0.9850 - val_loss: 2.7483 - val_acc: 0.5657\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 16s 19ms/step - loss: 0.0662 - acc: 0.9838 - val_loss: 2.6140 - val_acc: 0.5758\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 17s 22ms/step - loss: 0.0365 - acc: 0.9900 - val_loss: 2.9072 - val_acc: 0.5960\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 21s 26ms/step - loss: 0.0273 - acc: 0.9875 - val_loss: 3.0002 - val_acc: 0.5859\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 27s 34ms/step - loss: 0.0732 - acc: 0.9700 - val_loss: 2.7543 - val_acc: 0.6061\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 33s 42ms/step - loss: 0.0291 - acc: 0.9900 - val_loss: 2.8830 - val_acc: 0.6061\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 31s 39ms/step - loss: 0.0456 - acc: 0.9825 - val_loss: 2.8163 - val_acc: 0.6162\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 27s 34ms/step - loss: 0.0414 - acc: 0.9888 - val_loss: 2.7564 - val_acc: 0.6263\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 25s 31ms/step - loss: 0.0198 - acc: 0.9938 - val_loss: 3.1050 - val_acc: 0.6162\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 23s 29ms/step - loss: 0.0251 - acc: 0.9913 - val_loss: 3.1512 - val_acc: 0.5657\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 23s 29ms/step - loss: 0.0221 - acc: 0.9925 - val_loss: 2.9533 - val_acc: 0.5859\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 22s 28ms/step - loss: 0.0311 - acc: 0.9888 - val_loss: 3.0212 - val_acc: 0.5960\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 23s 29ms/step - loss: 0.0326 - acc: 0.9888 - val_loss: 2.8139 - val_acc: 0.5960\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 24s 30ms/step - loss: 0.0214 - acc: 0.9900 - val_loss: 2.7860 - val_acc: 0.6061\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 25s 31ms/step - loss: 0.0193 - acc: 0.9938 - val_loss: 2.9012 - val_acc: 0.6162\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 27s 33ms/step - loss: 0.0204 - acc: 0.9925 - val_loss: 2.9064 - val_acc: 0.5859\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 27s 34ms/step - loss: 0.0436 - acc: 0.9863 - val_loss: 3.0473 - val_acc: 0.6061\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 28s 34ms/step - loss: 0.0244 - acc: 0.9900 - val_loss: 3.0720 - val_acc: 0.6061\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 27s 34ms/step - loss: 0.0169 - acc: 0.9925 - val_loss: 3.1103 - val_acc: 0.5657\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 28s 35ms/step - loss: 0.0300 - acc: 0.9888 - val_loss: 3.0881 - val_acc: 0.5556\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 29s 36ms/step - loss: 0.0361 - acc: 0.9900 - val_loss: 3.1191 - val_acc: 0.5657\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 28s 35ms/step - loss: 0.0206 - acc: 0.9950 - val_loss: 3.1756 - val_acc: 0.5859\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 31s 39ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 3.1053 - val_acc: 0.5556\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 32s 40ms/step - loss: 0.0155 - acc: 0.9925 - val_loss: 3.1458 - val_acc: 0.6061\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 35s 43ms/step - loss: 0.0245 - acc: 0.9900 - val_loss: 2.8934 - val_acc: 0.5657\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 35s 43ms/step - loss: 0.0277 - acc: 0.9925 - val_loss: 2.8142 - val_acc: 0.6263\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 35s 44ms/step - loss: 0.0266 - acc: 0.9888 - val_loss: 3.1288 - val_acc: 0.5960\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 38s 47ms/step - loss: 0.0230 - acc: 0.9913 - val_loss: 3.1670 - val_acc: 0.5960\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 38s 48ms/step - loss: 0.0166 - acc: 0.9938 - val_loss: 3.1764 - val_acc: 0.5758\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 41s 51ms/step - loss: 0.0298 - acc: 0.9913 - val_loss: 3.2321 - val_acc: 0.6162\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 44s 55ms/step - loss: 0.0259 - acc: 0.9938 - val_loss: 3.2156 - val_acc: 0.6162\n",
      "Saved trained model at /Users/saggarwal/leaf_identification/saved_models/keras_leaf_combined_model_v2.h5 \n",
      "90/90 [==============================] - 1s 10ms/step\n",
      "Test loss: 4.981169086032444\n",
      "Test accuracy: 0.44444444709353975\n"
     ]
    }
   ],
   "source": [
    "# Let's train the model using RMSprop\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 99\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "# num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_leaf_combined_model_v2.h5'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_model, Y_train_model,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test_model, Y_test_model),\n",
    "          shuffle=True)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_val_model, Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add given numerical features to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (5, 5), padding=\"same\", input_shape=(96, 96, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "def combined_model():\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # First convolutional layer\n",
    "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = Concatenate()([x, numerical])\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "comb_model = combined_model()\n",
    "print('Model created!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/100\n",
      "801/801 [==============================] - 7s 8ms/step - loss: 4.5645 - acc: 0.0449\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 5s 7ms/step - loss: 3.7341 - acc: 0.1673\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 3.0636 - acc: 0.2921\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 6s 7ms/step - loss: 2.4631 - acc: 0.4519\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 6s 8ms/step - loss: 2.0745 - acc: 0.4744\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 7s 8ms/step - loss: 1.6245 - acc: 0.5943\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 6s 8ms/step - loss: 1.3638 - acc: 0.6529\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 7s 8ms/step - loss: 1.0995 - acc: 0.7191\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 7s 8ms/step - loss: 1.0497 - acc: 0.7416\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.9041 - acc: 0.7728\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.8253 - acc: 0.7915\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.6695 - acc: 0.8464\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.5849 - acc: 0.8552\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.4917 - acc: 0.8764\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.5345 - acc: 0.8664\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.4325 - acc: 0.8876\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.3771 - acc: 0.9064\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.3319 - acc: 0.9164\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.2746 - acc: 0.9326\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.2548 - acc: 0.9338\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.2452 - acc: 0.9401\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.2967 - acc: 0.9089\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.1968 - acc: 0.9438\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.1745 - acc: 0.9476\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 7s 9ms/step - loss: 0.1775 - acc: 0.9526\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.1712 - acc: 0.9538\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.1242 - acc: 0.9713\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.1445 - acc: 0.9688\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 8s 10ms/step - loss: 0.1143 - acc: 0.9750\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.1266 - acc: 0.9625\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.1080 - acc: 0.9725\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.1133 - acc: 0.9725\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.0759 - acc: 0.9850\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.0969 - acc: 0.9688\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 9s 11ms/step - loss: 0.0927 - acc: 0.9788\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0730 - acc: 0.9763\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0772 - acc: 0.9875\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0876 - acc: 0.9763\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0852 - acc: 0.9775\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0847 - acc: 0.9838\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 0.0655 - acc: 0.9863\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 0.0698 - acc: 0.9825\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0605 - acc: 0.9813\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0721 - acc: 0.9813\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0632 - acc: 0.9825\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0471 - acc: 0.9888\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 11s 13ms/step - loss: 0.0484 - acc: 0.9900\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 12s 15ms/step - loss: 0.0483 - acc: 0.9863\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 0.0519 - acc: 0.9850\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 10s 12ms/step - loss: 0.0530 - acc: 0.9825\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 10s 13ms/step - loss: 0.0420 - acc: 0.9850\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 12s 15ms/step - loss: 0.0480 - acc: 0.9875\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 0.0497 - acc: 0.9900\n",
      "Epoch 54/100\n",
      "801/801 [==============================] - 12s 14ms/step - loss: 0.0330 - acc: 0.9913\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 12s 14ms/step - loss: 0.0452 - acc: 0.9888\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 11s 14ms/step - loss: 0.0233 - acc: 0.9950\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 12s 15ms/step - loss: 0.0423 - acc: 0.9875\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 12s 15ms/step - loss: 0.0397 - acc: 0.9888\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.0364 - acc: 0.9888\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.0298 - acc: 0.9925\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 13s 16ms/step - loss: 0.0320 - acc: 0.9925\n",
      "Epoch 62/100\n",
      "801/801 [==============================] - 12s 15ms/step - loss: 0.0194 - acc: 0.9925\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 14s 17ms/step - loss: 0.0315 - acc: 0.9913\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 0.0463 - acc: 0.9863\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0148 - acc: 0.9988\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0245 - acc: 0.9913\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0366 - acc: 0.9900\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0263 - acc: 0.9925\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0253 - acc: 0.9938\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0209 - acc: 0.9925\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 18s 23ms/step - loss: 0.0240 - acc: 0.9963\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 18s 22ms/step - loss: 0.0279 - acc: 0.9900\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0200 - acc: 0.9938\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0288 - acc: 0.9913\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0241 - acc: 0.9938\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0278 - acc: 0.9913\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 19s 24ms/step - loss: 0.0317 - acc: 0.9875\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 17s 22ms/step - loss: 0.0154 - acc: 0.9963\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0307 - acc: 0.9913\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0283 - acc: 0.9925\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0182 - acc: 0.9938\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0179 - acc: 0.9963\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0215 - acc: 0.9913\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0221 - acc: 0.9925\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0174 - acc: 0.9950\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0201 - acc: 0.9938\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0216 - acc: 0.9938\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0120 - acc: 0.9975\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0170 - acc: 0.9963\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0181 - acc: 0.9925\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0167 - acc: 0.9963\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0132 - acc: 0.9975\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0083 - acc: 0.9988\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0140 - acc: 0.9975\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0127 - acc: 0.9975\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0106 - acc: 0.9975\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0171 - acc: 0.9950\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.0196 - acc: 0.9963\n",
      "Saved trained model at /Users/saggarwal/leaf_identification/saved_models/leafnet_combined.h5 \n",
      "90/90 [==============================] - 1s 13ms/step\n",
      "Test loss: 1.2551588455835978\n",
      "Test accuracy: 0.7555555595291985\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "print('Training model...')\n",
    "history = comb_model.fit(x = {'image': X_train_images, 'numerical': X_train},\n",
    "                    y = y_train,\n",
    "                    batch_size = 100,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1\n",
    "                   )\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "combined_model_name = \"leafnet_combined.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, combined_model_name)\n",
    "comb_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = comb_model.evaluate(x = {'image': X_val_images, 'numerical': X_val}, y = Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 801 samples, validate on 99 samples\n",
      "Epoch 1/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0088 - acc: 0.9988 - val_loss: 0.5141 - val_acc: 0.8990\n",
      "Epoch 2/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.4642 - val_acc: 0.8990\n",
      "Epoch 3/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.5459 - val_acc: 0.9091\n",
      "Epoch 4/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.6141 - val_acc: 0.8990\n",
      "Epoch 5/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0245 - acc: 0.9938 - val_loss: 0.5016 - val_acc: 0.8889\n",
      "Epoch 6/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0180 - acc: 0.9950 - val_loss: 0.5070 - val_acc: 0.8990\n",
      "Epoch 7/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.4763 - val_acc: 0.9091\n",
      "Epoch 8/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0183 - acc: 0.9950 - val_loss: 0.5458 - val_acc: 0.8889\n",
      "Epoch 9/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.5310 - val_acc: 0.9091\n",
      "Epoch 10/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0103 - acc: 0.9988 - val_loss: 0.5115 - val_acc: 0.9293\n",
      "Epoch 11/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0126 - acc: 0.9950 - val_loss: 0.5428 - val_acc: 0.8990\n",
      "Epoch 12/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0171 - acc: 0.9913 - val_loss: 0.5675 - val_acc: 0.9091\n",
      "Epoch 13/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.4399 - val_acc: 0.8990\n",
      "Epoch 14/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0164 - acc: 0.9963 - val_loss: 0.4959 - val_acc: 0.8990\n",
      "Epoch 15/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.3908 - val_acc: 0.9192\n",
      "Epoch 16/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0289 - acc: 0.9875 - val_loss: 0.4619 - val_acc: 0.9091\n",
      "Epoch 17/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.4778 - val_acc: 0.9192\n",
      "Epoch 18/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0182 - acc: 0.9938 - val_loss: 0.7677 - val_acc: 0.8889\n",
      "Epoch 19/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0273 - acc: 0.9938 - val_loss: 0.5177 - val_acc: 0.8990\n",
      "Epoch 20/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0085 - acc: 0.9988 - val_loss: 0.4981 - val_acc: 0.9192\n",
      "Epoch 21/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 0.4361 - val_acc: 0.9091\n",
      "Epoch 22/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0102 - acc: 0.9975 - val_loss: 0.4559 - val_acc: 0.9192\n",
      "Epoch 23/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0136 - acc: 0.9975 - val_loss: 0.5322 - val_acc: 0.8889\n",
      "Epoch 24/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0120 - acc: 0.9975 - val_loss: 0.6307 - val_acc: 0.8889\n",
      "Epoch 25/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.4329 - val_acc: 0.9192\n",
      "Epoch 26/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0177 - acc: 0.9963 - val_loss: 0.4740 - val_acc: 0.8889\n",
      "Epoch 27/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.4267 - val_acc: 0.9091\n",
      "Epoch 28/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8990\n",
      "Epoch 29/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.5701 - val_acc: 0.8788\n",
      "Epoch 30/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.5259 - val_acc: 0.9192\n",
      "Epoch 31/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0173 - acc: 0.9925 - val_loss: 0.4820 - val_acc: 0.8889\n",
      "Epoch 32/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.6539 - val_acc: 0.8788\n",
      "Epoch 33/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0101 - acc: 0.9963 - val_loss: 0.5121 - val_acc: 0.9192\n",
      "Epoch 34/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.5406 - val_acc: 0.9091\n",
      "Epoch 35/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.4609 - val_acc: 0.9192\n",
      "Epoch 36/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0131 - acc: 0.9925 - val_loss: 0.6320 - val_acc: 0.9091\n",
      "Epoch 37/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0151 - acc: 0.9938 - val_loss: 0.4167 - val_acc: 0.9192\n",
      "Epoch 38/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0170 - acc: 0.9925 - val_loss: 0.5129 - val_acc: 0.9293\n",
      "Epoch 39/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.4522 - val_acc: 0.9293\n",
      "Epoch 40/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0122 - acc: 0.9988 - val_loss: 0.5195 - val_acc: 0.9192\n",
      "Epoch 41/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.6355 - val_acc: 0.9192\n",
      "Epoch 42/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.5809 - val_acc: 0.9293\n",
      "Epoch 43/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0059 - acc: 0.9975 - val_loss: 0.5069 - val_acc: 0.9192\n",
      "Epoch 44/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0223 - acc: 0.9925 - val_loss: 0.4787 - val_acc: 0.9192\n",
      "Epoch 45/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.6596 - val_acc: 0.9192\n",
      "Epoch 46/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.4416 - val_acc: 0.9495\n",
      "Epoch 47/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.4473 - val_acc: 0.9394\n",
      "Epoch 48/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.4450 - val_acc: 0.9293\n",
      "Epoch 49/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0113 - acc: 0.9950 - val_loss: 0.5782 - val_acc: 0.9091\n",
      "Epoch 50/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.5537 - val_acc: 0.9293\n",
      "Epoch 51/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.4668 - val_acc: 0.9394\n",
      "Epoch 52/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0166 - acc: 0.9938 - val_loss: 0.5047 - val_acc: 0.9192\n",
      "Epoch 53/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0301 - acc: 0.9925 - val_loss: 0.7556 - val_acc: 0.8889\n",
      "Epoch 54/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0085 - acc: 0.9950 - val_loss: 0.6399 - val_acc: 0.8990\n",
      "Epoch 55/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0103 - acc: 0.9988 - val_loss: 0.5375 - val_acc: 0.9192\n",
      "Epoch 56/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.3770 - val_acc: 0.9394\n",
      "Epoch 57/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.6861 - val_acc: 0.8788\n",
      "Epoch 58/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0168 - acc: 0.9938 - val_loss: 0.6914 - val_acc: 0.9091\n",
      "Epoch 59/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0165 - acc: 0.9963 - val_loss: 0.4152 - val_acc: 0.9192\n",
      "Epoch 60/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.5527 - val_acc: 0.8889\n",
      "Epoch 61/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.8990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0103 - acc: 0.9950 - val_loss: 0.5964 - val_acc: 0.8889\n",
      "Epoch 63/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.5366 - val_acc: 0.9192\n",
      "Epoch 64/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.6157 - val_acc: 0.9091\n",
      "Epoch 65/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0129 - acc: 0.9950 - val_loss: 0.5566 - val_acc: 0.9091\n",
      "Epoch 66/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.4131 - val_acc: 0.9293\n",
      "Epoch 67/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.9975 - val_loss: 0.5382 - val_acc: 0.9293\n",
      "Epoch 68/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0131 - acc: 0.9938 - val_loss: 0.6465 - val_acc: 0.9192\n",
      "Epoch 69/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0164 - acc: 0.9913 - val_loss: 0.5637 - val_acc: 0.9192\n",
      "Epoch 70/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0092 - acc: 0.9963 - val_loss: 0.8056 - val_acc: 0.8889\n",
      "Epoch 71/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0075 - acc: 0.9963 - val_loss: 0.8339 - val_acc: 0.8990\n",
      "Epoch 72/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.7365 - val_acc: 0.9091\n",
      "Epoch 73/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0125 - acc: 0.9950 - val_loss: 0.4393 - val_acc: 0.9394\n",
      "Epoch 74/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0121 - acc: 0.9938 - val_loss: 0.6021 - val_acc: 0.9293\n",
      "Epoch 75/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 0.4532 - val_acc: 0.9394\n",
      "Epoch 76/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6132 - val_acc: 0.9091\n",
      "Epoch 77/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0151 - acc: 0.9975 - val_loss: 0.6019 - val_acc: 0.9091\n",
      "Epoch 78/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0058 - acc: 0.9963 - val_loss: 0.6539 - val_acc: 0.8889\n",
      "Epoch 79/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0047 - acc: 0.9975 - val_loss: 0.5288 - val_acc: 0.9091\n",
      "Epoch 80/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.5237 - val_acc: 0.9192\n",
      "Epoch 81/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0088 - acc: 0.9963 - val_loss: 0.4925 - val_acc: 0.9293\n",
      "Epoch 82/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.5110 - val_acc: 0.9394\n",
      "Epoch 83/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 0.9988 - val_loss: 0.6361 - val_acc: 0.9192\n",
      "Epoch 84/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0183 - acc: 0.9963 - val_loss: 0.4162 - val_acc: 0.9293\n",
      "Epoch 85/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0064 - acc: 0.9963 - val_loss: 0.5173 - val_acc: 0.9192\n",
      "Epoch 86/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0081 - acc: 0.9963 - val_loss: 0.4723 - val_acc: 0.9394\n",
      "Epoch 87/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4967 - val_acc: 0.9293\n",
      "Epoch 88/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0083 - acc: 0.9963 - val_loss: 0.4972 - val_acc: 0.9091\n",
      "Epoch 89/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0088 - acc: 0.9963 - val_loss: 0.5777 - val_acc: 0.8990\n",
      "Epoch 90/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0059 - acc: 0.9975 - val_loss: 0.5896 - val_acc: 0.9192\n",
      "Epoch 91/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0067 - acc: 0.9975 - val_loss: 0.6032 - val_acc: 0.9091\n",
      "Epoch 92/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.9345 - val_acc: 0.8788\n",
      "Epoch 93/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0149 - acc: 0.9938 - val_loss: 0.5576 - val_acc: 0.9091\n",
      "Epoch 94/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.3967 - val_acc: 0.9192\n",
      "Epoch 95/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0164 - acc: 0.9938 - val_loss: 0.4962 - val_acc: 0.9293\n",
      "Epoch 96/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0246 - acc: 0.9913 - val_loss: 0.5093 - val_acc: 0.9394\n",
      "Epoch 97/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.5869 - val_acc: 0.8990\n",
      "Epoch 98/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.6419 - val_acc: 0.9192\n",
      "Epoch 99/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.5354 - val_acc: 0.9192\n",
      "Epoch 100/100\n",
      "801/801 [==============================] - 2s 3ms/step - loss: 0.0046 - acc: 0.9975 - val_loss: 0.6293 - val_acc: 0.9293\n",
      "Saved trained model at /Users/saggarwal/leaf_identification/saved_models/leafnet_combined_2.h5 \n",
      "90/90 [==============================] - 0s 665us/step\n",
      "Test loss: 2.527375586827596\n",
      "Test accuracy: 0.7555555595291985\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 99\n",
    "epochs = 100\n",
    "\n",
    "print('Training model...')\n",
    "history = comb_model.fit(x = {'image': X_train_images, 'numerical': X_train},\n",
    "                         y = y_train,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         validation_data=({'image': X_test_images, 'numerical': X_test}, Y_test_model),\n",
    "                         shuffle=True,\n",
    "                         verbose = 1\n",
    "                        )\n",
    "\n",
    "# Save model and weights\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "combined_model_name = \"leafnet_combined_2.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, combined_model_name)\n",
    "comb_model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = comb_model.evaluate(x = {'image': X_val_images, 'numerical': X_val}, y = Y_val_model, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
